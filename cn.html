
<!DOCTYPE html>

<head>
    <meta name="keywords" content="Guo Jingcai, 郭径材, Jingcai, Jingcai Guo, jing cai, polyu, 香港理工大学, the hong kong polytechnic university, waseda, 早稻田大学, waseda university, sichuan, 四川大学, sichuan university, UESTC, 电子科技大学, University of Electronic Science and Technology of China, zero-shot learning, multimedia, federated learning, computer vision, cyber security, data mining, artificial intelligence, AI, machine learning">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-179394887-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    
    gtag('config', 'UA-179394887-1');
    </script>
    
    <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="description" content="Jingcai Guo (郭径材)">
    <meta name="author" content="Jingcai Guo (郭径材)">
    <meta property="og:description" content="Jingcai Guo (郭径材)">
    <link rel="stylesheet" href="./styles/jemdoc.css" type="text/css" />
    <title>Jingcai Guo (郭径材)</title>
    <!-- MathJax -->
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } } });
    </script>
    <!-- End MathJax -->
</head>

<body>
    <div id="layout-content">
        <p><br /></p>
        <h1><b>Jingcai Guo (郭 径材) &nbsp<a href="index.html"><font size="+1"><b>[English Version of This Page]</b></font></a></b></h1> 
        <p><img src="./imgs/Jingcai_Guo.jpg" width=200 align="right" offset="100px" style="padding:10px;" />
            <b>Ph.D., MIEEE, MACM, MCCF</b> <br /> </p>

        <a href="https://www.comp.polyu.edu.hk/" target=&ldquo;blank&rdquo;>电子计算学系 (COMP)</a><br />
        <a href="https://www.polyu.edu.hk/feng/" target=&ldquo;blank&rdquo;>工程学院</a><br />
        <a href="https://www.polyu.edu.hk/web/en/home/index.html" target=&ldquo;blank&rdquo;>香港理工大学</a> <br /> 
        </p>
        <p><b>通讯地址:</b> 香港特别行政区 香港理工大学 电子计算学系 PQ509室.<br />
        <b>电子邮箱:</b> [jingcai.guo AT gmail.com]</p>
    
    </p>
       <p><b><font style="color:#FF0000;"> [我已加入 西南财经大学 经济信息工程学院，欢迎各位有志于科研领域的同学报考我的研究生] </font></b><br />

           <p><br />  <br /></p>
            <center><i>"Life is painting a <b>picture</b>, not doing a <b>sum</b>"</i></center>
    
            <h2>个人简介</h2>
           
            <p align="justify"> 郭径材博士毕业于<a href = "https://www.polyu.edu.hk/">香港理工大学</a>, 电子计算学系, 导师为
                        <a href = "https://www.comp.polyu.edu.hk/en-us/staffs/detail/4511"><b>Song Guo (郭嵩) 教授</b></a>, 教育部长江讲席教授, Fellow of IEEE, Fellow of AAIA, 加拿大工程院院士。
                        从2019到2020, 郭径材作为访问研究员在<a href = "https://sydney.edu.au/">澳大利亚悉尼大学</a>开展研究工作, 
                        合作导师为<a href = "https://sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html"><b>Dacheng Tao (陶大程) 教授</b></a>, Fellow of IEEE, ACM, AAAS, IAPR, OSA, SPIE, IET/IEE, BCS, 澳洲科学院院士, 欧洲科学院外籍院士。
                        在此之前, 他从<a href = "https://www.waseda.jp/top/en">日本早稻田大学</a>获得硕士学位, 
                        导师为<a href = "https://www.waseda.jp/fsci/gips/other-en/2015/09/08/2170/"><b>Furuzuki Takayuki (古月敬之) 教授</b></a>; 
                        并从<a href = "http://en.scu.edu.cn/">四川大学</a>获得学士学位; 均为计算机科学方向。</p>
                        
            <p align="justify"> 他的研究兴趣广泛地涉及多媒体和人工智能领域, 尤其集中在零次学习 (zero-shot learning)、联邦学习 (federated learning)、计算机视觉 (computer vision)、信息安全 (cybersecurity) 和智能交通 (smart transportation) 等方面; 研究成果一贯发表在计算机相关领域顶级会议 (CCF-A/B类) 和高水平期刊 (中科院1区/JCR-Q1)。 
                            他是若干计算机领域国际顶级会议和高水平期刊的程序委员会委员或审稿人 (AAAI、IEEE ICME、IEEE DataCom、IEEE TMM、IEEE TKDE、IEEE IoTJ、IEEE TII, IEEE TETC 等); 
                            是IEEE/ACM/CCF会员; 
                          是香港政府资助 Hong Kong Ph.D. Fellowship 获得者 (2017)。</p>
            
        </p>
        <!--
            <h2>近期更新</h2>
            <div class="infoblock">
                <div class="blockcontent">
                    <ul>
                        <li>
                            <p>[ 02/2021 ] <font style="color:rgb(255, 0, 0);"><b>[New]</font></b> 我们的综述论文 <i>"On-device Learning Systems for Edge Intelligence: A Software and Hardware Synergy Perspective"</i> 被期刊 <a href="https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6488907"><i>IEEE Internet of Things Journal (IoTJ)</i></a> 全文接收.
                            </p>
                        </li>
                        
                        
                        <li>
                            <p>[ 2020/08 ] <font style="color:rgb(255, 0, 0);"><b>[New]</font></b> 我们的论文 <i>"Dual-view Attention Networks for Single Image Super-Resolution"</i> 被第28届 <a href="https://2020.acmmm.org/"><i>ACM International Conference on Multimedia (ACM MM 2020)</i></a> 全文接收, 将于美国西雅图举办。
                            </p>
                        </li>

                        <li>
                            <p>[ 2020/04 ] 我们的论文 <i>"A Novel Perspective to Zero-shot Learning: Towards an Alignment of Manifold Structures via Semantic Feature Expansion"</i> 被期刊 <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046"><i>IEEE Transactions on Multimedia (TMM)</i></a> 全文接收.
                            </p>
                        </li>

                        <li>
                            <p>[ 2019/09 ] 我将于2019.09 至 2020.03作为访问研究员访问 <a href="https://www.sydney.edu.au/">澳大利亚悉尼大学</a>, 并和 <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Prof. Dacheng Tao (陶大程教授)</a> 一同展开工作.
                            </p>
                        </li>

                        <li>
                            <p>[ 2019/03 ] 我们的论文 <i>"AMS-SFE: Towards an Alignment of Manifold Structures via Semantic Feature Expansion for Zero-shot Learnin"</i> 被第20届 <a href="https://signalprocessingsociety.org/blog/icme-2019-2019-ieee-international-conference-multimedia-and-expo"><i>IEEE International Conference on Multimedia and Expo (ICME 2019)</i></a> 全文接收, 将于中国上海举办。
                            </p>
                        </li>

                        <li>
                            <p>[ 2019/02 ] 我们的2篇论文 <i>"EE-AE: An Exclusivity Enhanced Unsupervised Feature Learning Approach"</i> 和 <i>"Adaptive Adjustment with Semantic Feature Space for Zero-Shot Recognition"</i> 被第44届 <a href="http://www.2019.ieeeicassp.org/ICASSP%202019/2019.ieeeicassp.org/index.html"><i>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2019)</i></a> 全文接收, 将于英国布莱顿举办。
                        </li>
                        
                    </ul>
                </div>
            </div>
        -->
            <h2>教育背景</h2>
            <ul>
<!-- MathJax -->
                    <P>
                    <li>
                    <font style="color:#527bbd;"><b>博士（Ph.D.):</b></font>&nbsp 香港理工大学,&nbsp 2017/09 - 2020/12 <br>
                    导师: <font style="color:#527bbd;">Prof. Song Guo, IEEE Fellow</font>. <br>
                    论文: <font style="color:#527bbd;"><i>Learning Robust Visual-semantic Mapping for Zero-shot Learning</i></font>. <br>
                    委员会成员: Prof. Song Guo (香港理工大学, IEEE Fellow), Prof. Baochun Li (多伦多大学, IEEE Fellow), Prof. Qingfu Zhang (香港城市大学, IEEE Fellow), Prof. Xiapu Luo (香港理工大学)
                    </p>

                    <P>
                    <li>
                    <font style="color:#527bbd;"><b>硕士 (M.E.):</b></font>&nbsp 日本早稻田大学,&nbsp 2013/09 - 2015/09 <br>
                    导师: <font style="color:#527bbd;">Prof. Furuzuki Takayuki</font>. <br>
                    论文: <font style="color:#527bbd;"><i>An Improved Incremental Training Approach for Support Vector Machine</i></font>. <br>
                    委员会成员: Prof. Furuzuki Takayuki (早稻田大学), Prof. IWAIHARA Mizuho (早稻田大学) and Prof. KAMATA Sei-ichiro (早稻田大学)
                    </p>
                    
                    <P>
                    <li>
                    <font style="color:#527bbd;"><b>学士 (B.E.):</b></font>&nbsp 四川大学,&nbsp 2009/09 - 2013/06
                    </p>
            </ul>


            <h2>学术工作经历</h2>
            <ul>



                    <P>
                    <li>
                    <font style="color:#527bbd;"><b>访问研究员 (Visiting Researcher):</b></font>&nbsp 澳大利亚悉尼大学,&nbsp 2019/09 - 2020/03 <br>
                    </p>
            </ul>



            <h2>论文发表</h2>

            <h3>正式发表</h3>

            <ul>
            <li>
            <p><font style="color:#527bbd;"><b>[TNNLS]</font></b>&nbsp <a href="https://ieeexplore.ieee.org/document/9503108" target=&ldquo;blank&rdquo;>
                Conservative Novelty Synthesizing Network for Malware Recognition in an Open-set Scenario</a>, <br /> 
                <u><b><font size=4>J. Guo</font></b></u>, S. Guo, S. Ma, Y. Sun, and Y. Xu. <br />
                IEEE Transactions on Neural Networks and Learning Systems (TNNLS). <br /> 
                (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385" target=&ldquo;blank&rdquo;><font style="color:#FF0000;"><b>JCR-Q1/中科院1区</b></font></a>, 计算机神经网络领域顶级期刊, IF=10.451, Early Access).<br /> 
                [<a href="./citation/iotj2021.txt" target=&ldquo;blank&rdquo;>BibTeX</a>]
                [<a href="./citation/iotj2021.ris" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
            </li>
            </ul>

            <ul>
            <li>
            <p><font style="color:#527bbd;"><b>[USENIX-ATC]</font></b>&nbsp <a href="https://www.usenix.org/conference/atc21" target=&ldquo;blank&rdquo;>
                INT8 Training with Loss-aware Compensation and Backward Quantization for Tiny On-device Learning</a>, <br />
                Q. Zhou, S. Guo, Z. Qu, <u><b><font size=4>J. Guo</font></b></u>, Z. Xu, J. Zhang, T. Guo, B. Luo, and J. Zhou. <br />
                in Proceedings of the 2021 USENIX Annual Technical Conference (USENIX ATC '21), virtual conference, 2021. <br /> 
                (<a href="https://www.ccf.org.cn/Academic_Evaluation/ARCH_DCP_SS/" target=&ldquo;blank&rdquo;><font style="color:#FF0000;"><b>CCF-A类</b></font></a>, 计算机体系结构领域顶级会议, H5-index=45).<br /> 
                [<a href="" target=&ldquo;blank&rdquo;>BibTeX</a>]
                [<a href="" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
            </li>
            </ul>

            <ul>
                <li>
                <p><font style="color:#527bbd;"><b>[IoTJ]</font></b>&nbsp <a href="https://ieeexplore.ieee.org/document/9366901" target=&ldquo;blank&rdquo;>
                    On-device Learning Systems for Edge Intelligence: A Software and Hardware Synergy Perspective</a>, <br /> 
                    Q. Zhou, Z. Qu, S. Guo, B. Luo, <u><b><font size=4>J. Guo</font></b></u>, Z. Xu, and R. Akerkar. <br />
                    IEEE Internet of Things Journal (IoTJ). <br /> 
                    (<a href="https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6488907" target=&ldquo;blank&rdquo;><font style="color:#FF0000;"><b>JCR-Q1/中科院1区</b></font></a>, 计算机物联网领域顶级期刊, IF=9.936, DOI: 10.1109/JIOT.2021.3063147).<br /> 
                    [<a href="./citation/iotj2021.txt" target=&ldquo;blank&rdquo;>BibTeX</a>]
                    [<a href="./citation/iotj2021.ris" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
                </li>
                </ul>
    
                <ul>
                <li>
                <p><font style="color:#527bbd;"><b>[ACM-MM]</font></b>&nbsp <a href="https://dl.acm.org/doi/10.1145/3394171.3413613" target=&ldquo;blank&rdquo;>
                    Dual-view Attention Networks for Single Image Super-Resolution</a>, <br /> 
                    <b><u><font size=4>J. Guo</font></u></b>, S. Ma, J. Zhang, Q. Zhou, and S. Guo.<br />
                    in Proceedings of the 28th ACM International Conference on Multimedia (ACM-MM '20), Seattle, WA, USA, 2020.<br />  
                    (<a href="https://www.ccf.org.cn/Academic_Evaluation/CGAndMT/" target=&ldquo;blank&rdquo;><font style="color:#FF0000;"><b>CCF-A类</b></font></a>, 计算机多媒体领域顶级会议, H5-index=58, DOI: 10.1145/3394171.3413613).<br /> 
                    <!--[<a href="./papers/pdf" target=&ldquo;blank&rdquo;>Pdf</a>]-->
                    [<a href="./citation/acmmm2020.txt" target=&ldquo;blank&rdquo;>BibTeX</a>]
                    [<a href="./citation/acmmm2020.ris" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
                </li>
                </ul>
    
                <ul>
                <li>
                <p><font style="color:#527bbd;"><b>[TMM]</font></b>&nbsp <a href="https://ieeexplore.ieee.org/document/9055169" target=&ldquo;blank&rdquo;>
                    A Novel Perspective to Zero-shot Learning: Towards an Alignment of Manifold Structures via Semantic Feature Expansion</a>, <br /> 
                    <u><b><font size=4>J. Guo</font></b></u> and S. Guo.<br />
                    IEEE Transactions on Multimedia (TMM).<br />  
                    (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046" target=&ldquo;blank&rdquo;><font style="color:#FF0000;"><b>JCR-Q1/中科院1区</b></font></a>, 计算机多媒体领域顶级期刊, IF = 6.051, DOI: 10.1109/TMM.2020.2984091).<br /> 
                    [<a href="./citation/tmm2020.txt" target=&ldquo;blank&rdquo;>BibTeX</a>]
                    [<a href="./citation/tmm2020.ris" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
                    </li>
                </ul>
    
                <ul>
                <li>
                <p><font style="color:#527bbd;"><b>[ICASSP]</font></b>&nbsp <a href="https://ieeexplore.ieee.org/document/8682869" target=&ldquo;blank&rdquo;>
                    Adaptive Adjustment with Semantic Feature Space for Zero-Shot Recognition</a>, <br /> 
                    <u><b><font size=4>J. Guo</font></b></u> and S. Guo. <br />
                    in Proceedings of the 44th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP '19), Brighton, United Kingdom, 2019.<br />  
                    (<a href="https://www.ccf.org.cn/Academic_Evaluation/CGAndMT/" target=&ldquo;blank&rdquo;><font style="color:#FF0000;"><b>CCF-B类</b></font></a>, 计算机信号处理和多媒体领域顶级会议, H5-index=86, DOI: DOI: 10.1109/ICASSP.2019.8682869).<br /> 
                    [<a href="./citation/icassp2019_adazsl.txt" target=&ldquo;blank&rdquo;>BibTeX</a>]
                    [<a href="./citation/icassp2019_adazsl.ris" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
                    </li>
                </ul>
    
    
                <ul>
                <li>
                <p><font style="color:#527bbd;"><b>[ICASSP]</font></b>&nbsp <a href="https://ieeexplore.ieee.org/document/8682891" target=&ldquo;blank&rdquo;>
                    EE-AE: An Exclusivity Enhanced Unsupervised Feature Learning Approach</a>, <br /> 
                    <u><b><font size=4>J. Guo</font></b></u> and S. Guo.<br />
                    in Proceedings of the 44th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP '19), Brighton, United Kingdom, 2019.<br />  
                    (<a href="https://www.ccf.org.cn/Academic_Evaluation/CGAndMT/" target=&ldquo;blank&rdquo;><font style="color:#FF0000;"><b>CCF-B类</b></font></a>, 计算机信号处理和多媒体领域顶级会议, H5-index=86, DOI: 10.1109/ICASSP.2019.8682891).<br /> 
                    [<a href="./citation/icassp2019_eeae.txt" target=&ldquo;blank&rdquo;>BibTeX</a>]
                    [<a href="./citation/icassp2019_eeae.ris" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
                </li>
                </ul>
    
                <ul>
                <li>
                <p><font style="color:#527bbd;"><b>[ICME]</font></b>&nbsp <a href="https://ieeexplore.ieee.org/document/8784887" target=&ldquo;blank&rdquo;>
                    AMS-SFE: Towards an Alignment of Manifold Structures via Semantic Feature Expansion for Zero-shot Learning</a>, <br /> 
                    <u><b><font size=4>J. Guo</font></b></u> and S. Guo.<br />
                    in Proceedings of the 20th IEEE International Conference on Multimedia and Expo (ICME '19), Shanghai, China, 2019.<br />  
                    (<a href="https://www.ccf.org.cn/Academic_Evaluation/CGAndMT/" target=&ldquo;blank&rdquo;><font style="color:#FF0000;"><b>CCF-B类</b></font></a>, 计算机多媒体领域旗舰会议, H5-index=30, DOI: 10.1109/ICME.2019.00021).<br /> 
                    [<a href="./citation/icme2019.txt" target=&ldquo;blank&rdquo;>BibTeX</a>]
                    [<a href="./citation/icme2019.ris" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
                </li>
                </ul>
    
                <ul>
                <li>
                <p><font style="color:#527bbd;"><b>[BDCAT]</font></b>&nbsp <a href="https://ieeexplore.ieee.org/document/7877062" target=&ldquo;blank&rdquo;>
                    An improved incremental training approach for large scaled dataset based on support vector machine</a>, <br /> 
                    <u><b><font size=4>J. Guo</font></b></u>.<br />
                    in Proceedings of the 3rd IEEE/ACM International Conference on Big Data Computing, Applications and Technologies (BDCAT '16), Association for Computing Machinery, New York, NY, USA, 2016. <br />  
                    (<a href="paper pdf" target=&ldquo;blank&rdquo;><b>EI</b></a>, DOI: 10.1145/3006299.3006307).<br /> 
                    [<a href="./citation/bdcat2016.txt" target=&ldquo;blank&rdquo;>BibTeX</a>]
                    [<a href="./citation/bdcat2016.ris" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
                </li>
                </ul>
    
                <ul>
                <li>
                <p><font style="color:#527bbd;"><b>[ARXIV]</font></b>&nbsp <a href="https://arxiv.org/pdf/1904.06187.pdf" target=&ldquo;blank&rdquo;>
                    Position-Aware Convolutional Networks for Traffic Prediction</a>, <br /> 
                    S. Ma, <u><b><font size=4>J. Guo</font></b></u>, S. Guo and M. Guo.<br />
                    ARXIV Technical Report.<br />
                    (DOI: arXiv:1904.06187)<br /> 
                    [<a href="./citation/position_aware2019.txt" target=&ldquo;blank&rdquo;>BibTeX</a>]
                    [<a href="./citation/position_aware2019.ris" target=&ldquo;blank&rdquo;>EndNote</a>] </p>
                </li>
                </ul>
    


            <h3>投/审稿中</h3>
            由于 <u><b>"审稿双盲原则"</b></u>, 部分近期工作<u><b>暂不显示</b></u>, 列表会经常更新。



        
            <h2>项目经历</h2>

            <ul>
                <!--
                    <P>
                    <li>
                    联合零次学习与图神经网络的实体反欺诈关键问题研究
                    <br>
                    角色: <font style="color:#527bbd;"><b>主持</font></b>
                    <br>
                    资助机构: 国家自然科学基金 青年项目-62102327, 24万元, 2022.01-2024.12.
                  -->

                    <P>
                    <li>
                    Learning Robust Visual-semantic Mapping for Zero-shot Learning,
                    <br>
                    角色: <font style="color:#527bbd;"><b>主持</font></b>
                    <br>
                    资助机构: 香港研究资助局 (Hong Kong Research Grants Council), HKPFS-UGC/GEN/456/08,UGC/GEN/456/5/09, 89万港币, 2017-2020.
                  
                    <P>
                    <li>
                    面向边缘智能的资源配置与部署优化关键技术研究
                    <br>
                    角色: <font style="color:#527bbd;"><b>参与</font></b>
                    <br>
                    资助机构: 国家自然科学基金 面上项目-61872310, 64万元, 2019-2022.
                        
                    <P>
                    <li>
                    云边端协同学习架构与关键优化理论研究
                    <br>
                    角色: <font style="color:#527bbd;"><b>参与</font></b>
                    <br>
                    资助机构: 深圳市科技创新委员会 基础研究重点项目-JCYJ20200109142008673, 250万元, 2021-2023.
                     
                   <!--
                    <P>
                    <li>
                    Transnational Partnership for Excellent Research and Education in Big Data and Emergency Management
                    <br>
                    角色: <font style="color:#527bbd;"><b>参与</font></b>
                    <br>
                    资助机构: 挪威科研理事会 NRC (Norwegian Research Council) INTPART (International Partnerships for Excellent Education and Research) Programme, 2017-2020.
                  -->
                  </ul>

            
            <h2>教学经历</h2>

            <ul>
                    <P>
                    <li>
                    主讲, 数据结构 Data Structure, SWUFE, 2021秋季学期.

                    <P>
                    <li>
                    助教, B2B & B2C E-commerce and Management, PolyU, 2019春季学期.
                  
                    <P>
                    <li>
                    助教, Information Systems Project Management, PolyU, 2018秋季学期.
                  
                    <P>
                    <li>
                    助教, Big Data Analytics, PolyU, 2018春季学期.
                  
                    <P>
                    <li>
                    助教, Web Advertising and Web Publishing, PolyU, 2017秋季学期.
                  
                  </ul>

            
<h2>学术兼职</h2> 

<h3>国际会议程序委员会委员</h3>
<ul>
<li>AAAI Conference on Artificial Intelligence (<b>AAAI: 2021, 2022</b>)</li>	
<li>IEEE International Conference on Multimedia and Expo (<b>IEEE ICME: 2019, 2020, 2021</b>)</li>
<li>IEEE International Conference on Big Data Intelligence and Computing (<b>IEEE DataCom: 2018</b>)</li>
</ul>

<h3>期刊审稿人</h3>
<ul>
<li>IEEE Transactions on Multimedia (<b>IEEE TMM</b>)</li>
<li>IEEE Transactions on Knowledge and Data Engineering (<b>IEEE TKDE</b>)</li>
<li>IEEE Internet of Things Journal (<b>IEEE IoTJ</b>)</li>
<li>IEEE Transactions on Industrial Informatics (<b>IEEE TII</b>)</li>
<li>IEEE Transactions on Emerging Topics in Computing (<b>IEEE TETC</b>)</li>
<li>ACM Transactions on Intelligent Systems and Technology (<b>ACM TIST</b>)</li>
</ul>

<h3>编委会成员</h3>
<ul>
<li>Progress in Human Computer Interaction (2018/06-2020/06)</li>
</ul>
            
            
<h2>代表性荣誉</h2>

<ul>

        <li>香港政府博士奖学金 Hong Kong Ph.D. Fellowship<br> 
        资助率 ~= 1.7%, 231/14000, 香港政府研究资助局 Hong Kong Research Grants Council, 2017
        </li>
                                    
        <li>顶新国际奖学金 Ting Hsing International Scholarship<br>
        资助率 ~= 4.2%, 85/2000, 早稻田大学 & 顶新国际, 2013
        </li>
        
</ul>
            
            
<h2>资助机构</h2>
真诚地感谢如下机构为我的研究提供支持:
<br>
<br>
<br>
<!--<img src="./imgs/nsfc.jpeg" height="100"> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp -->
<img src="./imgs/RGC.jpg" height="100"> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
<img src="./imgs/polyu.jpg" height="100">&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
<img src="./imgs/waseda1.jpg" height="100">&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
<img src="./imgs/tinghsing.jpeg" height="100"><div style="display:inline-block;width:5px;"><script type="text/javascript" src="//rf.revolvermaps.com/0/0/7.js?i=0hdmm10vwtf&amp;m=1&amp;c=ff0000&amp;cr1=ffffff&amp;sx=0&amp;ds=35" async="async"></script></div>


</div>






</body>

</html>
